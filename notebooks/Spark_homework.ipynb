{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c31ce4f-80eb-4e86-b6e0-5ba5a4e99644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9498bd-5147-4c65-8e23-ad0b35aaccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/03 10:24:03 WARN Utils: Your hostname, ubuntu-focal resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/03/03 10:24:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/03 10:24:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/03 10:24:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97de7a02-d8f4-4fe2-92cc-49a6d302f463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0beffd9-aed0-4077-88c2-7aba87b7f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bb3096-6411-467f-974b-a59ee368fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e9bc39-8d10-4e0b-baf4-9920b40f6732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1897493 entries, 0 to 1897492\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   dispatching_base_num    object \n",
      " 1   pickup_datetime         object \n",
      " 2   dropOff_datetime        object \n",
      " 3   PUlocationID            float64\n",
      " 4   DOlocationID            float64\n",
      " 5   SR_Flag                 float64\n",
      " 6   Affiliated_base_number  object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 101.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72b9a83-0966-4d2c-97e5-548e305b694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899fa4f3-aad6-4739-a527-5009d19e669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf95b7ef-970a-4c96-b41b-2ee83b92ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82987c4-b657-45bc-a6a9-566dafb882df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/03 10:24:57 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 6\n",
      "CSV file: file:///home/vagrant/notebooks/fhv_tripdata_2019-10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2019/10/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f77f1b-e7c0-4773-aa56-209d84073d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4793331-d172-40bc-88e3-306d6cbe5516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cac308-0f6b-4ee7-8701-75c49da352df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c398a1d-872f-4221-b599-27af6ad8dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropOff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "    .select('pickup_date', 'dropOff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(F.to_date(df.pickup_datetime) == '2019-10-15') \\\n",
    "    .count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f563af9a-78d4-4efd-acbc-c2cc288a5c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhv_trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5905651-99a6-4af7-a07e-c9779984d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------+\n",
      "|    pickup_datetime|   dropOff_datetime|trip_length|\n",
      "+-------------------+-------------------+-----------+\n",
      "|2019-10-11 18:00:00|2091-10-11 18:30:00|     631152|\n",
      "|2019-10-28 09:00:00|2091-10-28 09:30:00|     631152|\n",
      "|2019-10-31 23:46:33|2029-11-01 00:13:00|      87672|\n",
      "|2019-10-01 21:43:42|2027-10-01 21:45:23|      70128|\n",
      "|2019-10-17 14:00:00|2020-10-18 00:00:00|       8794|\n",
      "|2019-10-26 21:26:00|2020-10-26 21:36:00|       8784|\n",
      "|2019-10-30 12:30:04|2019-12-30 13:02:08|       1464|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:54:33|       1056|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:21:11|       1056|\n",
      "|2019-10-01 13:41:00|2019-11-03 14:58:51|        793|\n",
      "|2019-10-01 13:47:17|2019-11-03 15:20:28|        793|\n",
      "|2019-10-01 07:21:12|2019-11-03 08:44:21|        793|\n",
      "|2019-10-01 06:11:45|2019-11-03 06:39:03|        792|\n",
      "|2019-10-01 05:36:30|2019-11-03 06:23:36|        792|\n",
      "|2019-10-01 19:09:17|2019-11-03 19:41:02|        792|\n",
      "|2019-10-01 11:59:55|2019-11-03 12:25:27|        792|\n",
      "|2019-10-01 16:02:13|2019-11-03 16:15:50|        792|\n",
      "|2019-10-01 19:02:14|2019-11-03 19:05:38|        792|\n",
      "|2019-10-01 09:43:15|2019-11-03 09:53:53|        792|\n",
      "|2019-10-01 10:04:24|2019-11-03 10:20:13|        792|\n",
      "+-------------------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pickup_datetime,\n",
    "    dropOff_datetime,\n",
    "    TIMESTAMPDIFF(HOUR, pickup_datetime, dropOff_datetime) as trip_length\n",
    "FROM\n",
    "    fhv_trips_data\n",
    "order by trip_length desc\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a4f85e-b9fb-44b2-8e68-a17e45a1a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c4b52d2-5e2a-4e70-96cc-d2d5ae899c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ac005d1-aba6-41d8-8aaf-8a0398dab48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from zones\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5980c9fe-9bb7-414e-9d09-0d94fcf0ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------------+\n",
      "|pickup_zone_id|                Zone|pickup_frequency|\n",
      "+--------------+--------------------+----------------+\n",
      "|             2|         Jamaica Bay|               1|\n",
      "|           105|Governor's Island...|               2|\n",
      "|           111| Green-Wood Cemetery|               5|\n",
      "|            30|       Broad Channel|               8|\n",
      "|           120|     Highbridge Park|              14|\n",
      "|            12|        Battery Park|              15|\n",
      "|           207|Saint Michaels Ce...|              23|\n",
      "|            27|Breezy Point/Fort...|              25|\n",
      "|           154|Marine Park/Floyd...|              26|\n",
      "|             8|        Astoria Park|              29|\n",
      "|           128|    Inwood Hill Park|              39|\n",
      "|           253|       Willets Point|              47|\n",
      "|            96|Forest Park/Highl...|              53|\n",
      "|            34|  Brooklyn Navy Yard|              57|\n",
      "|            59|        Crotona Park|              62|\n",
      "|            58|        Country Club|              77|\n",
      "|            99|     Freshkills Park|              89|\n",
      "|           190|       Prospect Park|              98|\n",
      "|            54|     Columbia Street|             105|\n",
      "|           217|  South Williamsburg|             110|\n",
      "+--------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select\n",
    "    PULocationID as pickup_zone_id,\n",
    "    Zone,\n",
    "    count(1) as pickup_frequency\n",
    "from\n",
    "    fhv_trips_data\n",
    "left join zones on PULocationID = LocationID\n",
    "group by pickup_zone_id, Zone\n",
    "order by pickup_frequency asc \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377dec4-714a-48aa-9328-25e974a4cf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
